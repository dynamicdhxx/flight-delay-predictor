{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ” Frequent Itemset Mining\n",
        "\n",
        "Discover patterns in flight delays using association rule mining.\n",
        "\n",
        "**Objectives:**\n",
        "- Find frequent route/carrier combinations that experience delays\n",
        "- Identify cascade delay patterns\n",
        "- Generate actionable association rules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Try to import mlxtend for association rules\n",
        "try:\n",
        "    from mlxtend.frequent_patterns import apriori, association_rules\n",
        "    from mlxtend.preprocessing import TransactionEncoder\n",
        "    MLXTEND_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"âš ï¸ mlxtend not installed. Install with: pip install mlxtend\")\n",
        "    MLXTEND_AVAILABLE = False\n",
        "\n",
        "COLORS = {'primary': '#2E86AB', 'secondary': '#A23B72', 'warning': '#F18F01'}\n",
        "print(\"âœ“ Libraries imported\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "df = pd.read_csv('../data/processed/flights_cleaned.csv')\n",
        "\n",
        "# Create transaction items for delayed flights\n",
        "delayed_flights = df[df['is_delayed'] == 1].copy()\n",
        "print(f\"Total delayed flights: {len(delayed_flights):,}\")\n",
        "\n",
        "# Create item columns\n",
        "route_col = [c for c in df.columns if 'route' in c.lower()]\n",
        "carrier_col = [c for c in df.columns if 'airline' in c.lower() or 'carrier' in c.lower()]\n",
        "\n",
        "items_df = pd.DataFrame()\n",
        "if route_col:\n",
        "    items_df['route'] = 'ROUTE_' + delayed_flights[route_col[0]].astype(str)\n",
        "if carrier_col:\n",
        "    items_df['carrier'] = 'CARRIER_' + delayed_flights[carrier_col[0]].astype(str)\n",
        "\n",
        "# Add time-based items\n",
        "if 'hour' in df.columns:\n",
        "    items_df['time'] = delayed_flights['hour'].apply(lambda x: f\"HOUR_{x:02d}\" if pd.notna(x) else None)\n",
        "if 'day_of_week' in df.columns:\n",
        "    days = ['MON', 'TUE', 'WED', 'THU', 'FRI', 'SAT', 'SUN']\n",
        "    items_df['day'] = delayed_flights['day_of_week'].apply(lambda x: f\"DAY_{days[int(x)]}\" if pd.notna(x) else None)\n",
        "\n",
        "print(f\"Created {len(items_df.columns)} item categories\")\n",
        "display(items_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Association Rule Mining\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if MLXTEND_AVAILABLE and len(items_df) > 0:\n",
        "    # Convert to transactions\n",
        "    transactions = items_df.values.tolist()\n",
        "    transactions = [[item for item in tx if pd.notna(item)] for tx in transactions]\n",
        "    \n",
        "    # One-hot encode\n",
        "    te = TransactionEncoder()\n",
        "    te_array = te.fit_transform(transactions)\n",
        "    df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
        "    \n",
        "    # Find frequent itemsets\n",
        "    frequent_itemsets = apriori(df_encoded, min_support=0.01, use_colnames=True)\n",
        "    frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(len)\n",
        "    \n",
        "    print(f\"Found {len(frequent_itemsets)} frequent itemsets\")\n",
        "    display(frequent_itemsets.sort_values('support', ascending=False).head(15))\n",
        "    \n",
        "    # Generate association rules\n",
        "    if len(frequent_itemsets) > 0:\n",
        "        rules = association_rules(frequent_itemsets, metric='lift', min_threshold=1.0)\n",
        "        rules = rules.sort_values('lift', ascending=False)\n",
        "        print(f\"\\nFound {len(rules)} association rules with lift > 1.0\")\n",
        "        \n",
        "        if len(rules) > 0:\n",
        "            # Display top rules\n",
        "            display(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(15))\n",
        "            \n",
        "            # Visualize rules\n",
        "            fig, ax = plt.subplots(figsize=(10, 6))\n",
        "            ax.scatter(rules['support'], rules['confidence'], c=rules['lift'], \n",
        "                      cmap='viridis', alpha=0.6, s=50)\n",
        "            plt.colorbar(ax.collections[0], label='Lift')\n",
        "            ax.set_xlabel('Support')\n",
        "            ax.set_ylabel('Confidence')\n",
        "            ax.set_title('Association Rules: Support vs Confidence')\n",
        "            plt.savefig('../reports/figures/association_rules.png', dpi=150)\n",
        "            plt.show()\n",
        "else:\n",
        "    print(\"Performing basic frequency analysis instead...\")\n",
        "    # Simple frequency analysis as fallback\n",
        "    for col in items_df.columns:\n",
        "        print(f\"\\n{col.upper()} frequency in delayed flights:\")\n",
        "        print(items_df[col].value_counts().head(10))\n",
        "\n",
        "print(\"\\nâœ“ Itemset mining complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
