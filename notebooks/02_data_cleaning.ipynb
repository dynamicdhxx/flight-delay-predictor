{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ§¹ Data Cleaning & Feature Engineering\n",
        "\n",
        "This notebook handles data preprocessing and feature engineering for flight delay prediction.\n",
        "\n",
        "**Dataset:** Kaggle Flight Analytics Dataset  \n",
        "**Source:** https://www.kaggle.com/datasets/goyaladi/flight-dataset\n",
        "\n",
        "**Objectives:**\n",
        "- Handle missing values and outliers\n",
        "- Encode categorical variables  \n",
        "- Create derived features (temporal, route, carrier)\n",
        "- Prepare data for modeling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "sys.path.insert(0, os.path.abspath('..'))\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from src.data_processing import *\n",
        "from src.features import *\n",
        "\n",
        "print(\"âœ“ Libraries imported\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data - Try Kaggle dataset first, fallback to sample data\n",
        "from src.sample_data import load_kaggle_dataset, generate_sample_dataset\n",
        "\n",
        "kaggle_path = '../data/raw/Flight_data.csv'\n",
        "sample_path = '../data/raw/flights.csv'\n",
        "\n",
        "if os.path.exists(kaggle_path):\n",
        "    print(\"Loading Kaggle Flight Analytics Dataset...\")\n",
        "    df = pd.read_csv(kaggle_path)\n",
        "    print(f\"âœ“ Loaded {len(df):,} records from Kaggle dataset\")\n",
        "elif os.path.exists(sample_path):\n",
        "    print(\"Loading sample dataset...\")\n",
        "    df = pd.read_csv(sample_path)\n",
        "    print(f\"âœ“ Loaded {len(df):,} records from sample dataset\")\n",
        "else:\n",
        "    print(\"Generating sample dataset...\")\n",
        "    df = generate_sample_dataset(n_flights=50000, save_path=sample_path)\n",
        "\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Overview & Missing Values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standardize column names\n",
        "df.columns = df.columns.str.strip().str.replace(' ', '_')\n",
        "print(f\"Columns after standardization: {list(df.columns)}\")\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nðŸ“Š Missing Values:\")\n",
        "missing = df.isnull().sum()\n",
        "missing_pct = (missing / len(df) * 100).round(2)\n",
        "missing_df = pd.DataFrame({'Count': missing, 'Percentage': missing_pct})\n",
        "display(missing_df[missing_df['Count'] > 0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Handle missing values\n",
        "# Identify delay column (may vary by dataset)\n",
        "delay_cols = [col for col in df.columns if 'delay' in col.lower()]\n",
        "print(f\"Delay columns found: {delay_cols}\")\n",
        "\n",
        "# Set primary delay column\n",
        "if delay_cols:\n",
        "    delay_col = [c for c in delay_cols if 'arrival' in c.lower()]\n",
        "    delay_col = delay_col[0] if delay_col else delay_cols[0]\n",
        "    df['arrival_delay'] = pd.to_numeric(df[delay_col], errors='coerce').fillna(0)\n",
        "else:\n",
        "    # Create synthetic delay if missing\n",
        "    print(\"Creating synthetic delay column...\")\n",
        "    np.random.seed(42)\n",
        "    df['arrival_delay'] = np.random.normal(5, 25, len(df)).clip(-30, 180)\n",
        "\n",
        "# Create binary target\n",
        "df['is_delayed'] = (df['arrival_delay'] >= 15).astype(int)\n",
        "print(f\"\\nâœ“ Delay target created: {df['is_delayed'].mean()*100:.1f}% delayed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract route components if available\n",
        "route_col = [col for col in df.columns if 'route' in col.lower()]\n",
        "if route_col:\n",
        "    route_col = route_col[0]\n",
        "    route_split = df[route_col].str.split('-', expand=True)\n",
        "    if route_split.shape[1] >= 2:\n",
        "        df['origin'] = route_split[0].str.strip()\n",
        "        df['destination'] = route_split[1].str.strip()\n",
        "        print(f\"âœ“ Extracted origin/destination from route\")\n",
        "\n",
        "# Check for existing temporal columns or create them\n",
        "date_cols = [col for col in df.columns if 'date' in col.lower() or 'departure' in col.lower()]\n",
        "if date_cols:\n",
        "    # Try to parse date\n",
        "    for col in date_cols:\n",
        "        try:\n",
        "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "            if df[col].notna().sum() > 0:\n",
        "                df['hour'] = df[col].dt.hour\n",
        "                df['day_of_week'] = df[col].dt.dayofweek\n",
        "                df['month'] = df[col].dt.month\n",
        "                print(f\"âœ“ Extracted temporal features from {col}\")\n",
        "                break\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "# If no date found, check for existing temporal columns\n",
        "if 'hour' not in df.columns:\n",
        "    hour_col = [c for c in df.columns if 'hour' in c.lower()]\n",
        "    if hour_col:\n",
        "        df['hour'] = df[hour_col[0]]\n",
        "        \n",
        "print(f\"\\nDataset shape after feature engineering: {df.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Encode Categorical Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Identify categorical columns to encode\n",
        "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "# Exclude name-like columns\n",
        "cat_cols = [c for c in cat_cols if 'name' not in c.lower() and 'id' not in c.lower()]\n",
        "\n",
        "print(f\"Categorical columns to encode: {cat_cols}\")\n",
        "\n",
        "# Label encode categorical variables\n",
        "encoders = {}\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[f'{col}_encoded'] = le.fit_transform(df[col].astype(str))\n",
        "    encoders[col] = le\n",
        "    print(f\"  âœ“ Encoded {col}: {df[col].nunique()} unique values\")\n",
        "\n",
        "print(f\"\\nâœ“ Encoding complete. New shape: {df.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Prepare Final Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select features for modeling\n",
        "feature_cols = [col for col in df.columns if col.endswith('_encoded') or col in ['hour', 'day_of_week', 'month']]\n",
        "feature_cols = [col for col in feature_cols if col in df.columns]\n",
        "\n",
        "# Add numeric columns\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "numeric_cols = [c for c in numeric_cols if c not in ['is_delayed', 'arrival_delay'] \n",
        "                and 'delay' not in c.lower() and 'satisfaction' not in c.lower()]\n",
        "\n",
        "feature_cols = list(set(feature_cols + numeric_cols))\n",
        "print(f\"Features for modeling ({len(feature_cols)}): {feature_cols}\")\n",
        "\n",
        "# Create final dataset\n",
        "X = df[feature_cols].copy()\n",
        "y = df['is_delayed'].copy()\n",
        "\n",
        "# Handle any remaining NaN\n",
        "X = X.fillna(X.median())\n",
        "\n",
        "print(f\"\\nâœ“ Final feature matrix: {X.shape}\")\n",
        "print(f\"âœ“ Target distribution: {y.value_counts().to_dict()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save processed data\n",
        "df.to_csv('../data/processed/flights_cleaned.csv', index=False)\n",
        "X.to_csv('../data/processed/features.csv', index=False)\n",
        "y.to_csv('../data/processed/target.csv', index=False)\n",
        "\n",
        "print(\"âœ“ Saved processed data to data/processed/\")\n",
        "print(\"  - flights_cleaned.csv\")\n",
        "print(\"  - features.csv\") \n",
        "print(\"  - target.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
